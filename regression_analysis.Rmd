---
title: "regression_analysis"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, warning = FALSE)
```

```{r, include=FALSE}
library(tidyverse)
library(readxl)
library(knitr)
library(patchwork)
library(glmnet)
library(modelr)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%",
  fig.retina = 2,
  dpi = 320
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

```{r, include=FALSE}
set.seed(123)
```

To build the regression model, I included `mean_mhlth`, `mean_depression`, `mean_access`, `mean_smoking`, `mean_binge`, `mean_sleep`, `mean_lpa`, `mean_diabetes`, `mean_bphigh`, `EI_proportion`, and `PO_proportion` because they represent key dimensions of community health, health behaviors, access to care, and socioeconomic conditions that are plausibly related to overall general health. Using these variables together helps capture multiple pathways influencing the outcome and reduces the risk of omitted-variable bias while improving the model’s explanatory power.

```{r, include=FALSE}
# Merge the dataset for regression analysis.
RECS_EI = read_csv("EDA/clean data/RECS_Energy_Insecurity.csv")
RECS_EI_code = read_xlsx("EDA/clean data/CodeBook_State_Level_Energy_Insecurity.xlsx")
PLACES = read_csv("EDA/clean data/PLACES_Census_Tract_Data.csv")
PLACES_code = read_csv("EDA/clean data/Codebook_PLACES.csv")

mental_health_vars = PLACES |>
  select(
    state_desc,
    county_name,
    tract_fips,
    mhlth_crude_prev,
    depression_crude_prev,
    access2_crude_prev,
    csmoking_crude_prev,
    binge_crude_prev,
    sleep_crude_prev,
    lpa_crude_prev,
    ghlth_crude_prev,
    diabetes_crude_prev,
    bphigh_crude_prev
  )

state_means =
  mental_health_vars |>
  group_by(state_desc) |>
  summarise(
    mean_mhlth = mean(mhlth_crude_prev, na.rm = TRUE),
    mean_depression = mean(depression_crude_prev, na.rm = TRUE),
    mean_access = mean(access2_crude_prev, na.rm = TRUE),
    mean_smoking = mean(csmoking_crude_prev, na.rm = TRUE),
    mean_binge = mean(binge_crude_prev, na.rm = TRUE),
    mean_sleep = mean(sleep_crude_prev, na.rm = TRUE),
    mean_lpa = mean(lpa_crude_prev, na.rm = TRUE),
    mean_glth = mean(ghlth_crude_prev, na.rm = TRUE),
    mean_diabetes = mean(diabetes_crude_prev, na.rm = TRUE),
    mean_bphigh = mean(bphigh_crude_prev, na.rm = TRUE)
  ) |>
  ungroup()

recs_vars =
  RECS_EI |>
  select(
    state,
    EI_proportion,
    PO_proportion
  )

regression_data =
  state_means |>
  rename(state = state_desc) |>
  left_join(recs_vars, by = "state")

```


### Multiple Linear Regression

Fit the model
```{r}
mlr_fit =
  lm(mean_glth ~ mean_mhlth + mean_depression + mean_access +
       mean_smoking + mean_binge + mean_sleep + mean_lpa +
       mean_diabetes + mean_bphigh + EI_proportion + PO_proportion,
     data = regression_data)

summary(mlr_fit) |> 
  broom::tidy(conf.int = TRUE) |> 
  select(term, estimate, conf.low, conf.high, p.value) |> 
  knitr::kable(digits = 3)
```

Check for key assumptions

```{r}
p1 =
  regression_data |>
  modelr::add_residuals(mlr_fit) |>
  modelr::add_predictions(mlr_fit) |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "red") +
  labs(x = "Fitted values", y = "Residuals",
       title = "Residuals vs Fitted")

p2 =
  ggplot(mlr_fit, aes(sample = .resid)) +
  stat_qq() +
  stat_qq_line() +
  labs(title = "Normal Q-Q Plot of Residuals")

p1 + p2
```

The residuals appear randomly scattered around zero without a clear pattern, suggesting that the linearity and constant variance assumptions are reasonably satisfied.

Most points fall close to the reference line, indicating that the residuals are approximately normally distributed. A few deviations at the tails are expected with small samples (n = 50), but overall the normality assumption is acceptable.

After fitting the MLR model, we apply stepwise selection to efficiently identify the most informative predictors while keeping the key electricity variables in the model.
```{r}
lower_model =
  lm(mean_glth ~ EI_proportion + PO_proportion,
     data = regression_data)

step_model =
  step(mlr_fit,
       scope = list(lower = formula(lower_model),
                    upper = formula(mlr_fit)),
       direction = "both",
       trace = FALSE)

summary(step_model) |>
  broom::tidy(conf.int = TRUE) |>
  select(term, estimate, conf.low, conf.high, p.value) |>
  knitr::kable(digits = 3)
```

The final model based on MLR results in:

### ELASTIC NET 

Because our EDA shows that the two electricity variables are strongly correlated, the MLR model is likely to produce unstable estimates. Using Elastic Net helps prevent overfitting while simultaneously stabilizing the coefficient estimates and shrinking unnecessary parameters toward zero. Hence, we expec that this may leads to a more robust and interpretable model.

We set $\alpha = 0.5$ to balance the Ridge and Lasso penalties within the Elastic Net framework. We then used `cv.glmnet()` to identify the optimal value of $\lambda$. This function performs 10-fold cross-validation by default, repeatedly splitting the data into ten parts, training the model on nine parts, and validating it on the remaining part to select the  $\lambda$ that minimizes the cross-validated error

```{r}
y <- regression_data$mean_glth

x <- regression_data |> 
  select(
    mean_mhlth, mean_depression, mean_access, mean_smoking,
    mean_binge, mean_sleep, mean_lpa, mean_diabetes, mean_bphigh,
    EI_proportion, PO_proportion
  ) |> 
  as.matrix()

cv_en <- cv.glmnet(x, y, alpha = 0.5)
lambda_best <- cv_en$lambda.min
fit_en <- glmnet(x, y, alpha = 0.5, lambda = lambda_best)

coef_en <- coef(fit_en)
coef_en

pred_en <- predict(fit_en, x) |> as.numeric()

r2_en <- 1 - sum((y - pred_en)^2) / sum((y - mean(y))^2)
r2_en
rmse_en <- sqrt(mean((y - pred_en)^2))
rmse_en
```

### Cross Validation

fit a base-level model that only depend on electronical variables. 

```{r}
mlr_basic =  lm(mean_glth ~EI_proportion * PO_proportion ,
     data = regression_data)

summary(mlr_basic) 
```

```{r}
cv_df =
  crossv_mc(regression_data, n = 100) |>
  mutate(
    train = map(train, as_tibble),
    test  = map(test, as_tibble)
  )

cv_df =
  cv_df |>
  mutate(
    # Model 1: Full MLR
    model_1 = map(train, \(df)
      lm(mean_glth ~ mean_mhlth + mean_depression + mean_access +
           mean_smoking + mean_binge + mean_sleep + mean_lpa +
           mean_diabetes + mean_bphigh + EI_proportion + PO_proportion,
         data = df)
    ),

    # Model 2: Elastic Net (refit λ for each split)
    model_2 = map(train, \(df) {
      y <- df$mean_glth
      X <- df |>
        dplyr::select(
          mean_mhlth, mean_depression, mean_access, mean_smoking,
          mean_binge, mean_sleep, mean_lpa, mean_diabetes, mean_bphigh,
          EI_proportion, PO_proportion
        ) |>
        as.matrix()

      cvfit <- cv.glmnet(X, y, alpha = 0.5)
      best_lambda <- cvfit$lambda.min
      glmnet(X, y, alpha = 0.5, lambda = best_lambda)
    }),

    # Model 3: Electricity-only + Interaction
    model_3 = map(train, \(df)
      lm(mean_glth ~ EI_proportion * PO_proportion, data = df)
    )
  )

cv_df =
  cv_df |>
  mutate(
    rmse_model_1 = map2_dbl(model_1, test, \(fit, df)
      rmse(fit, df)
    ),

    rmse_model_2 = map2_dbl(model_2, test, \(fit, df) {
      y_test <- df$mean_glth
      X_test <- df |>
        dplyr::select(
          mean_mhlth, mean_depression, mean_access, mean_smoking,
          mean_binge, mean_sleep, mean_lpa, mean_diabetes, mean_bphigh,
          EI_proportion, PO_proportion
        ) |> as.matrix()
      pred <- predict(fit, X_test) |> as.numeric()
      sqrt(mean((y_test - pred)^2))
    }),

    rmse_model_3 = map2_dbl(model_3, test, \(fit, df)
      rmse(fit, df)
    )
  )

```

```{r}
cv_df |>
  dplyr::select(starts_with("rmse")) |>
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) |>
  ggplot(aes(x = model, y = rmse, fill = model)) +
  geom_violin() +
  ggtitle("Comparison of RMSE Across Models")

```

Model based on Elastic Net achieves the lowest and most stable RMSE across the cross-validation replicates, indicating superior predictive performance and generalization ability. The full MLR model performs moderately well but shows higher variability, suggesting mild overfitting. The electricity-only model has the highest RMSE, confirming that electricity variables alone are insufficient to explain variations in mean_glth.

### Bootstrap
After fitting the MLR model, we applied the bootstrap to evaluate how stable our results are under repeated sampling. The usual regression output relies on assumptions such as normality and constant variance, which may not fully hold in our data. Bootstrap resampling lets us approximate the sampling distribution of key estimates directly from the data, providing more robust standard errors and confidence intervals. This helps us assess whether the model’s conclusions remain consistent across resampled datasets.

```{r}
boot_straps =
  regression_data |>
  modelr::bootstrap(n = 5000)

boot_results =
  boot_straps |>
  mutate(
    models = map(
      strap,
      \(s) {
        df = s$data

        Xb = df |>
          select(
            mean_mhlth, mean_depression, mean_access, mean_smoking,
            mean_binge, mean_sleep, mean_lpa, mean_diabetes, mean_bphigh,
            EI_proportion, PO_proportion
          ) |>
          as.matrix()

        yb = df$mean_glth

        cvb = cv.glmnet(Xb, yb, alpha = 0.5)
        cb = coef(cvb, s = cvb$lambda.min)

        tibble(
          term = rownames(cb),
          estimate = as.numeric(cb)
        )
      }
    )
  ) |>
  select(-strap) |>
  unnest(models) |>
  filter(term != "(Intercept)")

boot_se =
  boot_results |>
  group_by(term) |>
  summarize(boot_se = sd(estimate))

boot_se
```



